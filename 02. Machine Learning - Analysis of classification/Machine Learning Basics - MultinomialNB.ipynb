{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c89fcf78",
   "metadata": {},
   "source": [
    "# Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75ed0176",
   "metadata": {},
   "source": [
    "## Classifying animals with \"Naive Bayes\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 603,
   "id": "d5f274c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fat y(1) n(0)\n",
    "# short lesgs y(1) n(0)\n",
    "# barks y(1) n(0)\n",
    "\n",
    "# animals\n",
    "pig_1 = [1, 1, 0]\n",
    "pig_2 = [1, 1, 0]\n",
    "pig_3 = [1, 1, 0]\n",
    "\n",
    "dog_1 = [1, 1, 1]\n",
    "dog_2 = [0, 1, 1]\n",
    "dog_3 = [0, 1, 1]\n",
    "\n",
    "# will be used to test the answer\n",
    "unknown_1 = [1, 1, 1]\n",
    "unknown_2 = [1, 0, 0]\n",
    "unknown_3 = [0, 0, 1]\n",
    "\n",
    "test = [unknown_1, unknown_2, unknown_3]\n",
    "answer_test = [-1, 1, -1]\n",
    "\n",
    "# training data\n",
    "data = [pig_1, pig_2, pig_3, dog_1, dog_2, dog_3] # X\n",
    "\n",
    "# setting the correct ansers for \"data\"\n",
    "#  1: pig\n",
    "# -1: dog\n",
    "marks = [1, 1, 1, -1, -1, -1] # y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6822ca57",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 604,
   "id": "ca644969",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d6bc165",
   "metadata": {},
   "source": [
    "### Creating the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 605,
   "id": "a8cd4fde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The animal is: Dog\n"
     ]
    }
   ],
   "source": [
    "model = MultinomialNB()\n",
    "model.fit(data, marks)\n",
    "\n",
    "# predicting the unknown with the model created\n",
    "model.predict([unknown_1])[0]\n",
    "animal = 'Dog' if model.predict([unknown_1])[0] == -1 else 'Pig'\n",
    "\n",
    "print(f'The animal is: {animal}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98c906b7",
   "metadata": {},
   "source": [
    "### Testing the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c90ea3d1",
   "metadata": {},
   "source": [
    "Creating a manual way to check the answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 606,
   "id": "37494111",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total of right answers: 100.0%\n"
     ]
    }
   ],
   "source": [
    "model.predict(test)\n",
    "diff = model.predict(test) - answer_test\n",
    "rigth = [r for r in diff if r ==0]\n",
    "print(f\"Total of right answers: {(len(rigth) /len(test)*100)}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33b8c8c3",
   "metadata": {},
   "source": [
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa83cad0",
   "metadata": {},
   "source": [
    "## Classifying buyers in a WEB page\n",
    "### Project 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd7f1956",
   "metadata": {},
   "source": [
    "Same principle as above, but now instead of animals it is classification of possible buyers acording to the pages the users accessed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 607,
   "id": "86e52b2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# accesed \"home page\", acessed \"how it works\" page, acessed \"contact\" page, and last if the user bought anything (yes = 1, no = 0)\n",
    "# 1,0,1,1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79c99e66",
   "metadata": {},
   "source": [
    "Importing data from acesso.csv with _pandas_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 608,
   "id": "7bc166ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('acesso.csv')\n",
    "X = data[['acessou_home', 'acessou_como_funciona', 'acessou_contato']]\n",
    "y = data['comprou']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f30a970c",
   "metadata": {},
   "source": [
    "Spliting into train and test, fiting the model and testing its accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 609,
   "id": "9ed9860c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of correct guesses: 88.89%\n",
      "Total of elements: 9\n"
     ]
    }
   ],
   "source": [
    "X_train = X[:90]\n",
    "y_train = y[:90]\n",
    "\n",
    "X_test = X[-9:]\n",
    "y_test = y[-9:]\n",
    "\n",
    "# creating the model with the train dataset\n",
    "model = MultinomialNB()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# testing the results\n",
    "results = model.predict(X_test)\n",
    "diff = results - y_test\n",
    "\n",
    "correct = [i for i in diff if i == 0]\n",
    "total_correct = len(correct)\n",
    "total_element = len(X_test)\n",
    "correct_rate = 100* total_correct / total_element\n",
    "print(f'Percentage of correct guesses: {round(correct_rate, 2)}%')\n",
    "print(f'Total of elements: {total_element}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e807445",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65393767",
   "metadata": {},
   "source": [
    "### Project 2 - Course Search Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9b02576",
   "metadata": {},
   "source": [
    "A mini model to predict if a course is bought by the client considering some diferent factors from a data set. <br>\n",
    "- home : client cliked on the home page (0 no, 1 yes)\n",
    "- busca : name of the course searched by the client (descriptive)\n",
    "- logado : if the client made a log-in (0 no, 1 yes)\n",
    "- comprou : if the client bought the course (0 no, 1 yes) (dependent variable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 610,
   "id": "d0598a7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>home</th>\n",
       "      <th>busca</th>\n",
       "      <th>logado</th>\n",
       "      <th>comprou</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>algoritmos</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>java</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>algoritmos</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>ruby</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>ruby</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   home       busca  logado  comprou\n",
       "0     0  algoritmos       1        1\n",
       "1     0        java       0        1\n",
       "2     1  algoritmos       0        1\n",
       "3     1        ruby       1        0\n",
       "4     1        ruby       0        1"
      ]
     },
     "execution_count": 610,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading the data and spliting into X and y\n",
    "data = pd.read_csv('cursos.csv' )\n",
    "X_df= data[['home', 'busca', 'logado']]\n",
    "y_df = data['comprou']\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 611,
   "id": "36764004",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We are training the model with 900 itens\n",
      "We are testing the model with 100 itens\n",
      "\n",
      "Percentage of correct guesses: 82.0%\n",
      "Total of elements tested: 100\n"
     ]
    }
   ],
   "source": [
    "# Converting the categorical into numerical\n",
    "X_df = pd.get_dummies(X_df)\n",
    "\n",
    "# Getting the arrays\n",
    "X = X_df.values\n",
    "y = y_df.values\n",
    "\n",
    "# Splitting the data into train and test\n",
    "train_size = int(0.9 * len(y))\n",
    "test_size = int(len(y) - train_size) \n",
    "\n",
    "X_train = X[:train_size]\n",
    "y_train = y[:train_size]\n",
    "X_test = X[-test_size:]\n",
    "y_test = y[-test_size:]\n",
    "\n",
    "print(f'We are training the model with {len(X_train)} itens')\n",
    "print(f'We are testing the model with {len(X_test)} itens\\n')\n",
    "\n",
    "# Creating the model with the train dataset\n",
    "model = MultinomialNB()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predicting the result\n",
    "results = model.predict(X_test)\n",
    "diff = results - y_test\n",
    "\n",
    "correct = [i for i in diff if i == 0]\n",
    "total_correct = len(correct)\n",
    "total_element = len(X_test)\n",
    "correct_rate = 100* total_correct / total_element\n",
    "print(f'Percentage of correct guesses: {round(correct_rate, 2)}%')\n",
    "print(f'Total of elements tested: {total_element}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a34a8f26",
   "metadata": {},
   "source": [
    "## Creating a dummy model to compare our 82% accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 612,
   "id": "ab44c988",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total of 1's in y: 832\n",
      "Total len of y: 1000\n",
      "Total accuracy of the dummy model: 83.2%\n"
     ]
    }
   ],
   "source": [
    "# Testing with an \"All 1\" dummy model\n",
    "data = pd.read_csv('cursos.csv' )\n",
    "X_df= data[['home', 'busca', 'logado']]\n",
    "y_df = data['comprou']\n",
    "X_df = pd.get_dummies(X_df)\n",
    "X = X_df.values\n",
    "y = y_df.values\n",
    "print(f'Total of 1\\'s in y: {sum(y)}')\n",
    "print(f'Total len of y: {len(y)}')\n",
    "\n",
    "print(f'Total accuracy of the dummy model: {sum(y)/len(y)*100}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 613,
   "id": "22738ca5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total of 0's in y: 168\n",
      "Total len of y: 1000\n",
      "Total accuracy of the dummy model: 16.8%\n"
     ]
    }
   ],
   "source": [
    "# Testing with an \"All 0\" dummy model\n",
    "data = pd.read_csv('cursos.csv' )\n",
    "X_df= data[['home', 'busca', 'logado']]\n",
    "y_df = data['comprou']\n",
    "X_df = pd.get_dummies(X_df)\n",
    "X = X_df.values\n",
    "y = y_df.values\n",
    "print(f'Total of 0\\'s in y: {-1*(sum(y) - len(y))}')\n",
    "print(f'Total len of y: {len(y)}')\n",
    "\n",
    "print(f'Total accuracy of the dummy model: {-1*(sum(y) - len(y))/len(y)*100}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 614,
   "id": "54ea0ec1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total accuracy of the dummy model: 83.2%\n"
     ]
    }
   ],
   "source": [
    "# Creating a dummy model to test always with the highest outcome (1 in this case (832))\n",
    "data = pd.read_csv('cursos.csv' )\n",
    "X_df= data[['home', 'busca', 'logado']]\n",
    "y_df = data['comprou']\n",
    "X_df = pd.get_dummies(X_df)\n",
    "X = X_df.values\n",
    "y = y_df.values\n",
    "right_one = len(y[y==1])\n",
    "right_zero = len(y[y==0])\n",
    "accuracy_rate = max(right_one, right_zero)/len(y)\n",
    "\n",
    "print(f'Total accuracy of the dummy model: {accuracy_rate*100}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 615,
   "id": "878f8fab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    832\n",
       "0    168\n",
       "dtype: int64"
      ]
     },
     "execution_count": 615,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(y).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a393baba",
   "metadata": {},
   "source": [
    "Using `Counter` from _collections_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 616,
   "id": "beb8d47c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({1: 832, 0: 168})"
      ]
     },
     "execution_count": 616,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "Counter(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 617,
   "id": "1cd6a18c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_values([832, 168])"
      ]
     },
     "execution_count": 617,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(y).values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 618,
   "id": "9dbe3a2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_items([(1, 832), (0, 168)])"
      ]
     },
     "execution_count": 618,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(y).items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 619,
   "id": "00001278",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys([1, 0])"
      ]
     },
     "execution_count": 619,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(y).keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eae421c2",
   "metadata": {},
   "source": [
    "Using `Counter` from _collections_ to get values when non numerical variables for our generical dummy model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 620,
   "id": "c7f6418f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>home</th>\n",
       "      <th>busca</th>\n",
       "      <th>logado</th>\n",
       "      <th>comprou</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>algoritmos</td>\n",
       "      <td>1</td>\n",
       "      <td>sim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>java</td>\n",
       "      <td>0</td>\n",
       "      <td>sim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>algoritmos</td>\n",
       "      <td>0</td>\n",
       "      <td>sim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>ruby</td>\n",
       "      <td>1</td>\n",
       "      <td>nao</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>ruby</td>\n",
       "      <td>0</td>\n",
       "      <td>sim</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   home       busca  logado comprou\n",
       "0     0  algoritmos       1     sim\n",
       "1     0        java       0     sim\n",
       "2     1  algoritmos       0     sim\n",
       "3     1        ruby       1     nao\n",
       "4     1        ruby       0     sim"
      ]
     },
     "execution_count": 620,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('cursos_sn.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 621,
   "id": "0462d8e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "832"
      ]
     },
     "execution_count": 621,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(Counter(y).values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 622,
   "id": "1a2f68fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total accuracy of the dummy model: 83.2%\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('cursos_sn.csv' )\n",
    "X_df= data[['home', 'busca', 'logado']]\n",
    "y_df = data['comprou']\n",
    "X_df = pd.get_dummies(X_df)\n",
    "X = X_df.values\n",
    "y = y_df.values\n",
    "accuracy_rate = max(Counter(y).values())/len(y)\n",
    "\n",
    "print(f'Total accuracy of the dummy model: {accuracy_rate*100}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 623,
   "id": "f82dd72c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total accuracy of the dummy model: 82.0%\n"
     ]
    }
   ],
   "source": [
    "accuracy_rate = max(Counter(y_test).values())/len(y_test) # using y_test instead of \"y\". So we compare equivalent datasets\n",
    "print(f'Total accuracy of the dummy model: {accuracy_rate*100}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0fed4ad",
   "metadata": {},
   "source": [
    "## Testing a new dataset with Naive Bayes and comparing with Dummy model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 624,
   "id": "9a641b57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We are training the model with 800 itens\n",
      "We are testing the model with 100 itens\n",
      "\n",
      "Percentage of correct guesses: 82.0%\n",
      "Total of elements tested: 100\n",
      "Total accuracy of the dummy model: 82.0%\n"
     ]
    }
   ],
   "source": [
    "# Loading the data and spliting into X and y\n",
    "data = pd.read_csv('cursos.csv' )\n",
    "X_df= data[['home', 'busca', 'logado']]\n",
    "y_df = data['comprou']\n",
    "\n",
    "# Converting the categorical into numerical\n",
    "X_df = pd.get_dummies(X_df)\n",
    "\n",
    "# Getting the arrays\n",
    "X = X_df.values\n",
    "y = y_df.values\n",
    "\n",
    "# Splitting the data into train, test and validation\n",
    "train_percentage = 0.8\n",
    "test_percentage = 0.1\n",
    "\n",
    "train_size = int(train_percentage * len(y))\n",
    "test_size = int(test_percentage * len(y)) \n",
    "validation_size = len(y) - train_size - test_size\n",
    "\n",
    "X_train = X[0:train_size]\n",
    "y_train = y[0:train_size]\n",
    "X_test = X[train_size:train_size + test_size]\n",
    "y_test = y[train_size:train_size + test_size]\n",
    "X_valid = X[-validation_size:] \n",
    "y_valid = y[-validation_size:]\n",
    "\n",
    "print(f'We are training the model with {len(X_train)} itens')\n",
    "print(f'We are testing the model with {len(X_test)} itens\\n')\n",
    "\n",
    "# Creating the model with the train dataset\n",
    "model = MultinomialNB()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predicting the result\n",
    "results = model.predict(X_test)\n",
    "diff = results - y_test\n",
    "\n",
    "correct = [i for i in diff if i == 0]\n",
    "total_correct = len(correct)\n",
    "total_element = len(X_test)\n",
    "correct_rate = 100* total_correct / total_element\n",
    "print(f'Percentage of correct guesses: {round(correct_rate, 2)}%')\n",
    "print(f'Total of elements tested: {total_element}')\n",
    "\n",
    "# Dummy model\n",
    "# data = pd.read_csv('cursos_2.csv' )\n",
    "X_df= data[['home', 'busca', 'logado']]\n",
    "y_df = data['comprou']\n",
    "X_df = pd.get_dummies(X_df)\n",
    "X = X_df.values\n",
    "y = y_df.values\n",
    "accuracy_rate = max(Counter(y_test).values())/len(y_test)\n",
    "\n",
    "print(f'Total accuracy of the dummy model: {accuracy_rate*100}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "361d7282",
   "metadata": {},
   "source": [
    "## AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 625,
   "id": "2634d31b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of correct guesses with AdaBoost: 84.0%\n",
      "Total of elements: 100\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "# creating the model with the train dataset\n",
    "model = AdaBoostClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# testing the results\n",
    "results = model.predict(X_test)\n",
    "correct = (results == y_test)\n",
    "\n",
    "total_correct = sum(correct)\n",
    "total_element = len(X_test)\n",
    "correct_rate = 100* total_correct / total_element\n",
    "print(f'Percentage of correct guesses with AdaBoost: {round(correct_rate, 2)}%')\n",
    "print(f'Total of elements: {total_element}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fa1b1a7",
   "metadata": {},
   "source": [
    "## def a Function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "143d7c2f",
   "metadata": {},
   "source": [
    "Using a function to create a model with a `multinomialNB` and `AdaBoost` to compare it with the `DummyModel` <br>\n",
    "After, we will use the winning model to compare with the validation test sample that we separated earlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 626,
   "id": "0d29be8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of correct guesses with MultinomialNB(): 82.0%\n",
      "Percentage of correct guesses with AdaBoostClassifier(): 84.0%\n",
      "Percentage of correct guesses with DummyModel: 82.0%\n"
     ]
    }
   ],
   "source": [
    "def fit_and_predic(model, X_train, y_train, X_test, y_test):\n",
    "    model.fit(X_train, y_train)\n",
    "    results = model.predict(X_test)\n",
    "    \n",
    "    correct = (results == y_test)\n",
    "    total_correct = sum(correct)\n",
    "    total_element = len(X_test)\n",
    "    \n",
    "    correct_rate = 100* total_correct / total_element\n",
    "    print(f'Percentage of correct guesses with {model}: {round(correct_rate, 2)}%')\n",
    "    return correct_rate\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "model = MultinomialNB()\n",
    "fit_and_predic(model, X_train, y_train, X_test, y_test)\n",
    "\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "model = AdaBoostClassifier()\n",
    "fit_and_predic(model, X_train, y_train, X_test, y_test)\n",
    "\n",
    "accuracy_rate = max(Counter(y_test).values())/len(y_test)\n",
    "print(f'Percentage of correct guesses with DummyModel: {accuracy_rate*100}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 627,
   "id": "5887fd32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of correct guesses with MultinomialNB(): 82.0%\n",
      "Percentage of correct guesses with AdaBoostClassifier(): 84.0%\n",
      "Percentage of correct guesses with winner model on validation test: 85.0%\n",
      "Percentage of correct guesses with DummyModel: 82.0%\n"
     ]
    }
   ],
   "source": [
    "modelNB = MultinomialNB()\n",
    "resultadoMultinomial = fit_and_predic(modelNB, X_train, y_train, X_test, y_test)\n",
    "\n",
    "modelAda = AdaBoostClassifier()\n",
    "resultadoAdaBoost = fit_and_predic(modelAda, X_train, y_train, X_test, y_test)\n",
    "\n",
    "if resultadoMultinomial > resultadoAdaBoost:\n",
    "    vencedor = modelNB\n",
    "else:\n",
    "    vencedor = modelAda\n",
    "    \n",
    "def real_test(model, X_valid, y_valid):\n",
    "    result = model.predict(X_valid)\n",
    "    correct = (result == y_valid)\n",
    "    \n",
    "    total_correct = sum(correct)\n",
    "    total_element = len(y_valid)\n",
    "    \n",
    "    correct_rate = 100* total_correct / total_element\n",
    "    print(f'Percentage of correct guesses with winner model on validation test: {round(correct_rate, 2)}%')\n",
    "    \n",
    "real_test(vencedor, X_valid, y_valid)\n",
    "accuracy_rate = max(Counter(y_valid).values())/len(y_valid)\n",
    "print(f'Percentage of correct guesses with DummyModel: {accuracy_rate*100}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45a0a13d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
